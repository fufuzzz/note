#### window 下 安装 scrapy

- 安装 pywin32： 命令 `pip install pywin32`

- 去 `http://www.lfd.uci.edu/~gohlke/pythonlibs/#twisted ` 这个网址，找到 twisted 不同版本的包， cp后面就是python的版本， 比如 cp36对应的就是 python3.6 。 win32是32位的操作系统， amd64是64为的操作系统

  下载之后存放再本地目录，执行命令安装 `pip  install  本地存放的文件路径`

- 安装 `安装Microsoft Visual C++ Build Tools`

- 最后安装 scrapy ，  `pip install scrapy`



#### scrapy 的好处

- 封装了很多 逻辑方法， 简化操作
- 内部采用的 是 异步多线程 的方式， 抓取速度更快



#### 开始一个scrapy爬虫的基本操作

- 创建一个scrapy项目，命令 `scrapy  startproject  wxapp（项目名称）`

- 创建爬虫，进入到项目目录中，通过执行 `scrapy genspider wx（爬虫名称，不能和项目名称一样） dreawer.com(网站的域名)`

- 修改配置文件，编辑 `settings.py` 文件

  ```python
  # 注释掉 爬虫的协议文件
  # ROBOTSTXT_OBEY = True
  
  # 先打开注释，再 request_header 中加入 user-agent
  DEFAULT_REQUEST_HEADERS = {
      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
      'Accept-Language': 'en',
      'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36'
  }
  ```

- 使用命令启动爬虫，再项目的根目录中，执行 `scrapy crawl wx（爬虫名称）`

- 快速的 启动一个爬虫的 程序

  - 再项目的根目录下面，创建一个文件，一般叫做 `start.py`

  - 在 `start.py` 中编辑 如下代码

    ```python
    from scrapy import cmdline
    
    cmdline.execute('scrapy crawl wx --nolog'.split())
    
    # --nolog 不显示日志
    ```



#### 在 parse 方法中 获取 数据

```python
def parse(self, response):
    
    response.text  # 获取源代码
    response.body  # 获取源代码的二进制数据
    
    # 根据xpath的语法获取数据， xapth语法中可以直接加 /text()  和 /@src
    # 但是不能直接拿到值，需要通过 get() 或者 getall()  获取值部分
    # 如果返回的是一个对象，用get()
    # 如果返回的是多个对象，用 getall()
    # xpath方法返回的对象，可以继续使用 xpath 的 语法
    response.xpath(xpath的语法)
    
    response.css(css选择器) # 用法和xpath一样
```





#### 在pipeline处理数据的流程

- 在 爬虫文件中 通过 yield 返回数据

  ```python
  for title, img in zip(titles, imgs):
      data = {
          'title': title,
          'img': img
      }
  
      # 把 数据交给 pipeline处理
      yield data
  ```

- 在 配置文件中 打开 pipeline的注释

  ```python
  ITEM_PIPELINES = {
     'wxapp.pipelines.WxappPipeline': 300,
  }
  ```

- 在 pipeline.py 文件中 通过 process_item 方法 的 item 参数获取 数据

  ```python
  def process_item(self, item, spider):
      print(item)
      return item
  ```

  